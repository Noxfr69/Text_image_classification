{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\Projet_p4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import json\n",
    "\n",
    "#Change this with your own open ai API key, create one here : https://platform.openai.com/account/api-keys\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "#Set your api key\n",
    "openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset :\n",
    "#### Online shop items listed with their categories, name and description\n",
    "\n",
    "We will mainly use the product name in this notebook to save on the number of token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_tree</th>\n",
       "      <th>product_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Baby Care</td>\n",
       "      <td>Oren Empower Extra Large Self Adhesive Sticker</td>\n",
       "      <td>Oren Empower Extra Large Self Adhesive Sticker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>Baby Care</td>\n",
       "      <td>Wallmantra Large Vinyl Sticker Sticker</td>\n",
       "      <td>Wallmantra Large Vinyl Sticker Sticker (Pack o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Baby Care</td>\n",
       "      <td>Uberlyfe Extra Large Pigmented Polyvinyl Films...</td>\n",
       "      <td>Buy Uberlyfe Extra Large Pigmented Polyvinyl F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>Baby Care</td>\n",
       "      <td>Wallmantra Medium Vinyl Sticker Sticker</td>\n",
       "      <td>Buy Wallmantra Medium Vinyl Sticker Sticker fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>Baby Care</td>\n",
       "      <td>Uberlyfe Large Vinyl Sticker</td>\n",
       "      <td>Buy Uberlyfe Large Vinyl Sticker for Rs.595 on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_category_tree                                       product_name  \\\n",
       "1045             Baby Care     Oren Empower Extra Large Self Adhesive Sticker   \n",
       "1046             Baby Care             Wallmantra Large Vinyl Sticker Sticker   \n",
       "1047             Baby Care  Uberlyfe Extra Large Pigmented Polyvinyl Films...   \n",
       "1048             Baby Care            Wallmantra Medium Vinyl Sticker Sticker   \n",
       "1049             Baby Care                       Uberlyfe Large Vinyl Sticker   \n",
       "\n",
       "                                            description  \n",
       "1045  Oren Empower Extra Large Self Adhesive Sticker...  \n",
       "1046  Wallmantra Large Vinyl Sticker Sticker (Pack o...  \n",
       "1047  Buy Uberlyfe Extra Large Pigmented Polyvinyl F...  \n",
       "1048  Buy Wallmantra Medium Vinyl Sticker Sticker fo...  \n",
       "1049  Buy Uberlyfe Large Vinyl Sticker for Rs.595 on...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = pd.read_csv('./text_data.csv')\n",
    "text_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First goal is to create a string that we can pass to the model**\n",
    "\n",
    "We will format it as **index** : **product name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the product_name column into a numbered list format\n",
    "formatted_product_names = [f\"{i}: {x}\" for i, x in enumerate(text_data['product_name'].head(5))]\n",
    "\n",
    "# Convert the entire series into a single string\n",
    "products_string = ', '.join(formatted_product_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0: Elegance Polyester Multicolor Abstract Eyelet Door Curtain',\n",
       " '1: Sathiyas Cotton Bath Towel',\n",
       " '2: Eurospa Cotton Terry Face Towel Set',\n",
       " '3: SANTOSH ROYAL FASHION Cotton Printed King sized Double Bedsheet',\n",
       " '4: Jaipur Print Cotton Floral King sized Double Bedsheet']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_product_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0: Elegance Polyester Multicolor Abstract Eyelet Door Curtain, 1: Sathiyas Cotton Bath Towel, 2: Eurospa Cotton Terry Face Towel Set, 3: SANTOSH ROYAL FASHION Cotton Printed King sized Double Bedsheet, 4: Jaipur Print Cotton Floral King sized Double Bedsheet'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One of the limitation of LLMs is the number of tokens they can take as input**\n",
    "\n",
    "To understand or have an idea of how many tokens does our string is we can use the GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "tokens = tokenizer.tokenize(products_string)\n",
    "token_count = len(tokens)\n",
    "print(token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the gpt API work ?\n",
    "- create a ChatCompletion\n",
    "- specify a model (gpt-3.5-turbo, gpt4)\n",
    "- temperature higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n",
    "- messages, the contexte of the conversation, there are different roles:\n",
    "    - system : to set the models general role\n",
    "    - user : that's you\n",
    "    - assistant : that's the model, building contexte you can put words in its mouth to help him help you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"{\\n  \\\"0\\\": 4,\\n  \\\"1\\\": 1,\\n  \\\"2\\\": 1,\\n  \\\"3\\\": 4,\\n  \\\"4\\\": 4\\n}\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1692697699,\n",
      "  \"id\": \"chatcmpl-7qIHjeA7i6Z6VAysA4TQE27iiU8vT\",\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 37,\n",
      "    \"prompt_tokens\": 196,\n",
      "    \"total_tokens\": 233\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant tasked to classify text into 7 categories.\"},\n",
    "            {\"role\": \"user\", \"content\": \"here is a list of the categories: 1: Baby Care, 2: Beauty and Personal Care, 3: Computers, 4: Home Decor & Festive Needs, 5: Home Furnishing, 6: Kitchen & Dining, 7: Watches\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"How should I format my answer?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Answer in a json formating style {\\\"sentence index\\\" : category number}\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Okay give me sentences to categorize\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{products_string}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To get the json we just need to acces the message.content in the response.choices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"0\": 4,\\n  \"1\": 1,\\n  \"2\": 1,\\n  \"3\": 4,\\n  \"4\": 4\\n}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"0\": 4,\\n  \"1\": 1,\\n  \"2\": 1,\\n  \"3\": 4,\\n  \"4\": 4\\n}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the answer string :\n",
    "content = response.choices[0].message.content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 4, '1': 1, '2': 1, '3': 4, '4': 4}\n"
     ]
    }
   ],
   "source": [
    "#because we are expecing a json format we can directly load it like this:\n",
    "result = {}\n",
    "result = json.loads(response.choices[0].message.content)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty cool !\n",
    "**Let's now do it for the full dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = {}\n",
    "i = 0\n",
    "\n",
    "# Create a function to merge two dictionaries\n",
    "def merge_dicts(dict1, dict2):\n",
    "    merged_dict = {**dict1, **dict2}\n",
    "    return merged_dict\n",
    "\n",
    "while i < text_data.shape[0]:\n",
    "    # Take the text_data 100 rows by 100 rows to stay in the token limit\n",
    "    end_index = min(i + 100, text_data.shape[0])  # Handle the case where there's less than 100 rows left\n",
    "    \n",
    "    # Select the current chunk of 100 (or less) rows\n",
    "    current_chunk = text_data['product_name'].iloc[i:end_index]\n",
    "    \n",
    "    \n",
    "    formatted_product_names = [f\"{idx+i}: {x}\" for idx, x in enumerate(current_chunk)]\n",
    "\n",
    "    products_string = ', '.join(formatted_product_names)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant tasked to classify text into 7 categories.\"},\n",
    "            {\"role\": \"user\", \"content\": \"here is a list of the categories: 1: Baby Care, 2: Beauty and Personal Care, 3: Computers, 4: Home Decor & Festive Needs, 5: Home Furnishing, 6: Kitchen & Dining, 7: Watches\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"How should I format my answer?\"},\n",
    "            {\"role\": \"user\", \"content\": \"Answer in a json formating style {\\\"sentence index\\\" : category number}\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Okay give me sentences to categorize\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{products_string}\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    result = {}\n",
    "    for choice in response.choices:\n",
    "        result = json.loads(choice.message.content)\n",
    "    # Merge the results\n",
    "    result_json = merge_dicts(result_json, result)\n",
    "    \n",
    "    # Move to the next chunk of data\n",
    "    i += 100\n",
    "\n",
    "# Save the final combined results\n",
    "with open('result.json', 'w') as f_out:\n",
    "    json.dump(result_json, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you don't want to run it again, since it's not free you can just load the results :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result_gpt3.5.json', 'r') as f:\n",
    "    result_gpt3 = json.load(f)\n",
    "\n",
    "\n",
    "with open('./result_gpt4.json', 'r') as f:\n",
    "    result_gpt4 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Product Index  Category Number\n",
      "0                0                5\n",
      "1                1                5\n",
      "2                2                5\n",
      "3                3                5\n",
      "4                4                5\n",
      "...            ...              ...\n",
      "1045          1045                4\n",
      "1046          1046                4\n",
      "1047          1047                4\n",
      "1048          1048                4\n",
      "1049          1049                4\n",
      "\n",
      "[1050 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the JSON object to a DataFrame\n",
    "df_classification_gpt4 = pd.DataFrame(list(result_gpt4.items()), columns=['Product Index', 'Category Number'])\n",
    "df_classification_gpt3 = pd.DataFrame(list(result_gpt3.items()), columns=['Product Index', 'Category Number'])\n",
    "\n",
    "print(df_classification_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moment of truth how good is the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand index for gpt3: 0.45872756532020414\n",
      "Rand index for gpt4: 0.8027008491002728\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Rand index\n",
    "rand_index = adjusted_rand_score(text_data['product_category_tree'], df_classification_gpt3['Category Number'])\n",
    "print(f'Rand index for gpt3: {rand_index}')\n",
    "\n",
    "rand_index = adjusted_rand_score(text_data['product_category_tree'], df_classification_gpt4['Category Number'])\n",
    "print(f'Rand index for gpt4: {rand_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## And compared to traditional Text Transformation Techniques\n",
    "\n",
    "The traditional approach to handling text involves using algorithms to transform the text into vectors.\n",
    "\n",
    "Numerous algorithms exist for this purpose, ranging from simple word counting methods to more intricate techniques. Commonly, these algorithms incorporate processes like stemming, lemmatization, and the removal of punctuation and stopwords.\n",
    "\n",
    "For those interested, a small exploration can be found in the notebook titled `text_classification_p6`, where I experimented with `CountVectorizer`, `TfidfVectorizer`, `word2vec`, `USE` and `BERT`. This notebook is available in the same repository under the `image_text_classification` section.\n",
    "\n",
    "While it might not be entirely equitable to draw direct comparisons, below are the Rand indices I obtained for each of the models:\n",
    "\n",
    "- **TfidfVectorizer Rand index:** 0.49126859466672784 \n",
    "- **Word2vec Rand index:** 0.1925855267844711  \n",
    "- **BERT Rand index:** 0.4134534468309783  \n",
    "- **USE Rand index:** 0.4660123193298835  \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet_p4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
